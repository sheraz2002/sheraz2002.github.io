<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Mathematics for Machine Learning (Specialization) · Muhammad Sheraz</title>
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css"/>
  <link rel="stylesheet" href="../../styles.css"/>
</head>
<body>
  <div class="bg"></div>

  <nav class="nav glass container">
    <span class="logo">
      Muhammad Sheraz
      <a href="https://www.linkedin.com/in/msherazz/" target="_blank" class="nav-social"><i class="fab fa-linkedin"></i></a>
      <a href="https://github.com/dsshaizy/" target="_blank" class="nav-social"><i class="fab fa-github"></i></a>
      <a href="mailto:dsshaizy@gmail.com" class="nav-social"><i class="fas fa-envelope"></i></a>
    </span>
    <ul class="nav__links">
      <li><a href="../../index.html">Home</a></li>
      <!-- Navbar items switch the tabs on this page -->
      <li><a href="../../index.html?tab=ai#projects">AI Projects</a></li>
      <li><a href="../../index.html?tab=embedded#projects">Embedded & Control</a></li>
      <li><a href="../experience.html">Experience</a></li>
      <li><a href="../education.html" class="active">Education</a></li>
      <li><a href="../skills.html">Skills</a></li>
      <li><a href="../contact.html">Contact</a></li>
    </ul>
  </nav>

  <main class="container">
    <section class="project-page">
      <h1><span class="highlight">Mathematics</span> for <span class="highlight">Machine Learning</span> (Specialization)</h1>
      <div class="tags">Imperial College London · Coursera</div>

      <!-- Aligned Certificate button -->
      <p style="display:flex; align-items:center; justify-content:space-between; gap:1rem; margin:.75rem 0 1.25rem;">
        <strong>Certificate:</strong>
        <a href="https://www.coursera.org/account/accomplishments/specialization/CT2DHZ9MPDUJ" target="_blank" class="btn"
           style="padding:.3rem .9rem; border-radius:1.2rem; font-size:.9rem; white-space:nowrap; text-decoration:none; display:inline-flex; align-items:center; gap:.35rem;">
          View Credential <i class="fas fa-arrow-up-right-from-square"></i>
        </a>
      </p>

      <p><strong>Course Details:</strong> University-level math foundations tailored for machine learning practitioners and researchers.</p>
      <p><strong>Duration:</strong> ~2–3 months</p>

      <p><strong>Overview:</strong> Built the mathematical toolkit behind modern ML: <span class="highlight">Linear Algebra</span>, <span class="highlight">Multivariate Calculus</span>, and <span class="highlight">Principal Component Analysis (PCA)</span>. Emphasis on geometric intuition, matrix calculus for optimization, and dimensionality reduction.</p>

      <h3 class="skills-heading">What I Practiced</h3>
      <div class="skills-grid">
        <div class="skill-logo" title="Linear Algebra: Vectors, Matrices, Eigenvalues"><i class="fas fa-vector-square"></i><span>Linear Algebra</span></div>
        <div class="skill-logo" title="Calculus for ML: Gradients, Jacobians, Hessians"><i class="fas fa-square-root-alt"></i><span>Calculus · Gradients</span></div>
        <div class="skill-logo" title="Optimization: Gradient Descent, Least Squares"><i class="fas fa-chart-line"></i><span>Optimization</span></div>
        <div class="skill-logo" title="Dimensionality Reduction: PCA, Eigen Decomposition"><i class="fas fa-compress-arrows-alt"></i><span>PCA · SVD</span></div>
        <div class="skill-logo" title="Geometric & Analytical Intuition"><i class="fas fa-drafting-compass"></i><span>Geometric Intuition</span></div>
        <div class="skill-logo" title="Applied Math for ML Models"><i class="fas fa-robot"></i><span>Applied ML Math</span></div>
      </div>

      <h3 class="skills-heading">Key Learnings</h3>
      <ul>
        <li>Vector spaces, norms, orthogonality, eigenvalues/eigenvectors, and matrix decompositions.</li>
        <li>Matrix calculus: gradients, Jacobians, Hessians, and chain rule for matrix functions.</li>
        <li>Optimization foundations: convexity, least squares, and gradient-based optimization.</li>
        <li>Principal Component Analysis: covariance, eigen-decomposition, and variance maximization.</li>
        <li>Connections between mathematical abstractions and real ML algorithms.</li>
      </ul>

      <h3 class="skills-heading">Mini-Projects & Exercises</h3>
      <ul>
        <li>Implemented PCA: standardization → covariance → eigen-decomposition → dimensionality reduction.</li>
        <li>Derived and implemented linear regression with both analytical (normal equation) and gradient descent solutions.</li>
        <li>Visualized 2D/3D gradient fields and level sets to study optimization behavior.</li>
      </ul>

      <p><strong>Challenges Solved:</strong> Improved numerical stability in eigen-computations (centering/scaling), debugged gradient shapes with Jacobian checks, and resolved rank-deficient least squares using SVD.</p>

      <p><strong>Why it matters:</strong> These mathematical foundations make ML models interpretable and robust—understanding loss landscapes, feature spaces, and the logic behind optimization and dimensionality reduction.</p>
    </section>
  </main>

  <footer class="footer container">
    © <span id="year"></span> Muhammad Sheraz
  </footer>

  <script src="https://cdn.jsdelivr.net/npm/vanilla-tilt@1.7.3/dist/vanilla-tilt.min.js"></script>
  <script>
    document.getElementById("year").textContent = new Date().getFullYear();
  </script>
</body>
</html>
